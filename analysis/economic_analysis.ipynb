{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PoSyg Economic Model Analysis\n",
        "Token distribution, rewards, and stability mechanisms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import optimize\n",
        "import json\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Token Distribution Evolution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze wealth concentration over time\n",
        "def analyze_token_distribution(metrics_df):\n",
        "    # Calculate concentration metrics\n",
        "    gini_evolution = metrics_df['gini_coefficient']\n",
        "    \n",
        "    # Calculate Theil index approximation\n",
        "    theil_index = []\n",
        "    for _, row in metrics_df.iterrows():\n",
        "        # Approximate from Gini\n",
        "        g = row['gini_coefficient']\n",
        "        theil = -np.log(1 - g) if g < 1 else np.inf\n",
        "        theil_index.append(theil)\n",
        "    \n",
        "    # HHI (Herfindahl-Hirschman Index) approximation\n",
        "    hhi = gini_evolution ** 2 * 10000  # Scaled approximation\n",
        "    \n",
        "    return pd.DataFrame({\n",
        "        'epoch': metrics_df['epoch'],\n",
        "        'gini': gini_evolution,\n",
        "        'theil': theil_index,\n",
        "        'hhi': hhi\n",
        "    })"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Reward Optimization Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model optimal reward distribution\n",
        "def optimize_reward_distribution(validators_df, target_gini=0.4):\n",
        "    # Current state\n",
        "    stakes = validators_df['final_stake'].values\n",
        "    activities = validators_df['blocks_proposed'].values + validators_df['blocks_attested'].values * 0.1\n",
        "    governance = validators_df['governance_votes'].values\n",
        "    \n",
        "    # Normalize\n",
        "    stakes_norm = stakes / stakes.sum()\n",
        "    activities_norm = activities / max(activities.sum(), 1)\n",
        "    governance_norm = governance / max(governance.sum(), 1)\n",
        "    \n",
        "    # Optimization objective: minimize Gini while maintaining security\n",
        "    def objective(weights):\n",
        "        w_stake, w_activity, w_governance = weights\n",
        "        scores = w_stake * stakes_norm + w_activity * activities_norm + w_governance * governance_norm\n",
        "        \n",
        "        # Calculate Gini of resulting distribution\n",
        "        sorted_scores = np.sort(scores)\n",
        "        n = len(sorted_scores)\n",
        "        cumsum = np.cumsum(sorted_scores)\n",
        "        gini = (2 * np.sum((np.arange(1, n+1) * sorted_scores))) / (n * cumsum[-1]) - (n + 1) / n\n",
        "        \n",
        "        # Penalty for deviating from target\n",
        "        return (gini - target_gini) ** 2\n",
        "    \n",
        "    # Constraints: weights sum to 1, all positive\n",
        "    constraints = [\n",
        "        {'type': 'eq', 'fun': lambda w: w.sum() - 1},\n",
        "        {'type': 'ineq', 'fun': lambda w: w[0] - 0.2}  # Min stake weight for security\n",
        "    ]\n",
        "    \n",
        "    # Optimize\n",
        "    result = optimize.minimize(\n",
        "        objective, \n",
        "        x0=[0.4, 0.4, 0.2], \n",
        "        bounds=[(0.2, 0.8), (0.1, 0.7), (0.1, 0.5)],\n",
        "        constraints=constraints\n",
        "    )\n",
        "    \n",
        "    return {\n",
        "        'optimal_weights': result.x,\n",
        "        'achieved_gini': np.sqrt(result.fun) + target_gini,\n",
        "        'success': result.success\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Slashing Economics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze slashing impact on network economics\n",
        "def analyze_slashing_economics(validators_df, metrics_df):\n",
        "    # Group validators by slashing count\n",
        "    slash_groups = validators_df.groupby('slashing_count').agg({\n",
        "        'id': 'count',\n",
        "        'final_stake': ['mean', 'sum'],\n",
        "        'final_synergy_score': 'mean'\n",
        "    })\n",
        "    \n",
        "    # Calculate economic impact\n",
        "    total_initial_stake = 1000000  # Assuming 1M total initial stake\n",
        "    total_final_stake = validators_df['final_stake'].sum()\n",
        "    stake_burned = total_initial_stake - total_final_stake\n",
        "    \n",
        "    # Slashing effectiveness\n",
        "    slashed_validators = validators_df[validators_df['slashing_count'] > 0]\n",
        "    if len(slashed_validators) > 0:\n",
        "        avg_penalty_per_slash = (\n",
        "            (total_initial_stake / len(validators_df) - slashed_validators['final_stake'].mean()) / \n",
        "            slashed_validators['slashing_count'].mean()\n",
        "        )\n",
        "    else:\n",
        "        avg_penalty_per_slash = 0\n",
        "    \n",
        "    return {\n",
        "        'total_stake_burned': stake_burned,\n",
        "        'burn_rate': stake_burned / total_initial_stake,\n",
        "        'avg_penalty_per_slash': avg_penalty_per_slash,\n",
        "        'slashed_validator_ratio': len(slashed_validators) / len(validators_df),\n",
        "        'slash_groups': slash_groups\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Stability Fund Modeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model algorithmic stability fund behavior\n",
        "def model_stability_fund(market_volatility=0.3, fund_size_ratio=0.15, simulation_periods=365):\n",
        "    np.random.seed(42)\n",
        "    \n",
        "    # Initialize\n",
        "    peg_price = 1.0\n",
        "    market_price = peg_price\n",
        "    fund_size = fund_size_ratio * 1000000  # 15% of total supply\n",
        "    intervention_threshold = 0.05  # 5% deviation\n",
        "    \n",
        "    history = []\n",
        "    \n",
        "    for t in range(simulation_periods):\n",
        "        # Market shock (random walk with volatility)\n",
        "        shock = np.random.normal(0, market_volatility / np.sqrt(365))\n",
        "        market_price *= (1 + shock)\n",
        "        \n",
        "        # Calculate deviation\n",
        "        deviation = abs(market_price - peg_price) / peg_price\n",
        "        \n",
        "        # Fund intervention\n",
        "        intervention_amount = 0\n",
        "        if deviation > intervention_threshold:\n",
        "            # Intervention strength proportional to deviation\n",
        "            intervention_strength = min(deviation * 2, 0.5)\n",
        "            intervention_amount = fund_size * intervention_strength\n",
        "            \n",
        "            # Apply intervention (simplified)\n",
        "            if market_price > peg_price:\n",
        "                # Sell to reduce price\n",
        "                market_price *= (1 - intervention_strength * 0.1)\n",
        "            else:\n",
        "                # Buy to increase price\n",
        "                market_price *= (1 + intervention_strength * 0.1)\n",
        "            \n",
        "            # Reduce fund size\n",
        "            fund_size -= intervention_amount * 0.01  # Cost of intervention\n",
        "        \n",
        "        history.append({\n",
        "            'period': t,\n",
        "            'market_price': market_price,\n",
        "            'deviation': deviation,\n",
        "            'fund_size': fund_size,\n",
        "            'intervention': intervention_amount\n",
        "        })\n",
        "    \n",
        "    return pd.DataFrame(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Inflation and Supply Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model token supply and inflation\n",
        "def analyze_inflation_impact(initial_supply=1000000, inflation_rate=0.05, epochs=1000):\n",
        "    supply_history = [initial_supply]\n",
        "    \n",
        "    for epoch in range(1, epochs):\n",
        "        # Annual inflation converted to per-epoch\n",
        "        epoch_inflation = inflation_rate / 365\n",
        "        new_tokens = supply_history[-1] * epoch_inflation\n",
        "        supply_history.append(supply_history[-1] + new_tokens)\n",
        "    \n",
        "    # Calculate metrics\n",
        "    inflation_df = pd.DataFrame({\n",
        "        'epoch': range(epochs),\n",
        "        'total_supply': supply_history,\n",
        "        'epoch_inflation': np.diff([initial_supply] + supply_history),\n",
        "        'cumulative_inflation': (np.array(supply_history) - initial_supply) / initial_supply\n",
        "    })\n",
        "    \n",
        "    return inflation_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Economic Equilibrium Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Find economic equilibrium points\n",
        "def find_economic_equilibrium(validators_df, target_decentralization=0.6):\n",
        "    # Current state\n",
        "    gini = validators_df['final_stake'].sort_values()\n",
        "    n = len(gini)\n",
        "    cumsum = np.cumsum(gini)\n",
        "    current_gini = (2 * np.sum((np.arange(1, n+1) * gini))) / (n * cumsum[-1]) - (n + 1) / n\n",
        "    \n",
        "    # Target Gini for decentralization\n",
        "    target_gini = 1 - target_decentralization\n",
        "    \n",
        "    # Calculate required redistribution\n",
        "    if current_gini > target_gini:\n",
        "        # Need to redistribute from top to bottom\n",
        "        top_10_pct = validators_df.nlargest(int(n * 0.1), 'final_stake')\n",
        "        bottom_50_pct = validators_df.nsmallest(int(n * 0.5), 'final_stake')\n",
        "        \n",
        "        redistribution_needed = (\n",
        "            (current_gini - target_gini) * \n",
        "            validators_df['final_stake'].sum()\n",
        "        )\n",
        "        \n",
        "        return {\n",
        "            'current_gini': current_gini,\n",
        "            'target_gini': target_gini,\n",
        "            'redistribution_needed': redistribution_needed,\n",
        "            'top_10_stake_ratio': top_10_pct['final_stake'].sum() / validators_df['final_stake'].sum(),\n",
        "            'bottom_50_stake_ratio': bottom_50_pct['final_stake'].sum() / validators_df['final_stake'].sum()\n",
        "        }\n",
        "    else:\n",
        "        return {\n",
        "            'current_gini': current_gini,\n",
        "            'target_gini': target_gini,\n",
        "            'status': 'Already at or below target decentralization'\n",
        "        }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Comprehensive Economic Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate economic analysis report\n",
        "scenarios = ['baseline', 'cartel_attack', 'high_byzantine']\n",
        "economic_results = {}\n",
        "\n",
        "for scenario in scenarios:\n",
        "    try:\n",
        "        path = f\"results_{scenario}\"\n",
        "        metrics = pd.read_csv(f\"{path}/metrics_history.csv\")\n",
        "        validators = pd.read_csv(f\"{path}/final_validator_states.csv\")\n",
        "        \n",
        "        # Run all analyses\n",
        "        economic_results[scenario] = {\n",
        "            'distribution': analyze_token_distribution(metrics),\n",
        "            'optimal_weights': optimize_reward_distribution(validators),\n",
        "            'slashing': analyze_slashing_economics(validators, metrics),\n",
        "            'equilibrium': find_economic_equilibrium(validators)\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"Error analyzing {scenario}: {e}\")\n",
        "\n",
        "# Visualize key economic metrics\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "fig.suptitle('Economic Analysis Summary', fontsize=16)\n",
        "\n",
        "# Implementation of visualization code\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}